{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bJC7AAwL592Y"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fP8WPmaG592d"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ouL4PILE592g"
   },
   "outputs": [],
   "source": [
    "#Load the data\n",
    "data = pd.read_csv('../data/data.csv')\n",
    "relevent_data = data.drop('code_size', axis=1)\n",
    "test_app = 'consumer_tiffmedian'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z8UOWhyQ5928"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (pool1): MaxPool1d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (conv1): Conv1d(1, 10, kernel_size=(5,), stride=(1,), padding=(3,))\n",
       "  (conv2): Conv1d(10, 20, kernel_size=(5,), stride=(1,), padding=(3,))\n",
       "  (conv3): Conv1d(20, 10, kernel_size=(5,), stride=(1,), padding=(3,))\n",
       "  (conv4): Conv1d(10, 1, kernel_size=(5,), stride=(1,), padding=(3,))\n",
       "  (fc1): Linear(in_features=21, out_features=150, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc2): Linear(in_features=150, out_features=200, bias=True)\n",
       "  (batch_norm): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc3): Linear(in_features=200, out_features=100, bias=True)\n",
       "  (fc4): Linear(in_features=100, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from net import net\n",
    "losses = []\n",
    "net = net.to(device)\n",
    "net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2gULAIY1hs55"
   },
   "outputs": [],
   "source": [
    "def train_test_split(test_app):\n",
    "  train_data  = relevent_data[relevent_data['APP_NAME'] != test_app]\n",
    "  test_data = relevent_data[relevent_data['APP_NAME'] == test_app]\n",
    "  scaler = MinMaxScaler(feature_range=(0,1)).fit(relevent_data[relevent_data['APP_NAME'] != test_app].iloc[:,1:-5])\n",
    "  scaled_train_predictors = scaler.transform(relevent_data[relevent_data['APP_NAME'] != test_app].iloc[:,1:-5])\n",
    "  train_targets = relevent_data[relevent_data['APP_NAME'] != test_app].iloc[:,-5:]\n",
    "  scaled_train_targets = []\n",
    "  for app in range(0, train_targets.shape[0], 128):\n",
    "    scaled_train_targets.append(MinMaxScaler(feature_range=(0,1)).fit_transform(train_targets.iloc[app:app+128]))\n",
    "  scaled_train_targets = np.array(scaled_train_targets).reshape(train_targets.shape[0],5)\n",
    "  scaled_test_predictors = MinMaxScaler(feature_range=(0,1)).fit_transform(relevent_data[relevent_data['APP_NAME'] == test_app].iloc[:,1:-5])\n",
    "  scaled_test_targets = MinMaxScaler(feature_range=(0,1)).fit_transform(relevent_data[relevent_data['APP_NAME'] == test_app].iloc[:,-5:])\n",
    "  train_set = torch.tensor(\n",
    "      data=np.concatenate(\n",
    "          (\n",
    "              scaled_train_predictors,\n",
    "              scaled_train_targets\n",
    "          ),\n",
    "          axis=1\n",
    "      ),\n",
    "      dtype=torch.float\n",
    "      ).to(device)\n",
    "  test_set = torch.tensor(\n",
    "    data=np.concatenate(\n",
    "        (\n",
    "            scaled_test_predictors,\n",
    "            scaled_test_targets\n",
    "        ),\n",
    "        axis=1\n",
    "    ),\n",
    "    dtype=torch.float\n",
    "  ).to(device)\n",
    "  return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UhtMW9Ei592_"
   },
   "outputs": [],
   "source": [
    "#Set hyperparameters\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "lr=1e-4\n",
    "weight_decay = 1e-4\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "wsaE1mEp593D",
    "outputId": "ce5840d8-f907-4505-ffcc-8ff6292f26e3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "automotive_bitcount, epoch 49, train loss: 5.5290268659591675, test loss: 4.9391521364450455, average test_loss 4.904833242148161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "for test_app in relevent_data['APP_NAME'].unique():\n",
    "  train_set, test_set = train_test_split(test_app)\n",
    "  test_losses = []\n",
    "  #Training loop\n",
    "  for epoch in range(epochs):\n",
    "      \n",
    "      #Set train loss to zero\n",
    "      running_loss = 0.0\n",
    "      \n",
    "      #Shuffle training set\n",
    "      shuffled_train_set = train_set[torch.randperm(train_set.shape[0])]\n",
    "      \n",
    "      for start_index in range(0, shuffled_train_set.shape[0] - batch_size, batch_size):\n",
    "          #get batches\n",
    "          X = shuffled_train_set[start_index:start_index + batch_size, :-5].view(batch_size,1,285)\n",
    "          y = shuffled_train_set[start_index:start_index + batch_size, -5:]\n",
    "          \n",
    "          #zero gradients\n",
    "          optimizer.zero_grad()\n",
    "          \n",
    "          #forward pass\n",
    "          outputs = net(X).view(batch_size,5)\n",
    "          \n",
    "          #get loss\n",
    "          loss = criterion(outputs, y)\n",
    "          \n",
    "          #backward pass\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "          running_loss += loss.item()\n",
    "\n",
    "      #Set test loss to zero\n",
    "      test_loss = 0.0\n",
    "\n",
    "      #Shuffle test set\n",
    "      shuffled_test_set = test_set[torch.randperm(test_set.shape[0])]\n",
    "\n",
    "      for start_index in range(0, shuffled_test_set.shape[0] - batch_size, batch_size):\n",
    "\n",
    "          #get batches\n",
    "          X = shuffled_test_set[start_index:start_index + batch_size, :-5].view(batch_size,1,285)\n",
    "          y = shuffled_test_set[start_index:start_index + batch_size, -5:]\n",
    "\n",
    "          #forward pass\n",
    "          outputs = net(X).view(batch_size,5)\n",
    "\n",
    "          #get loss\n",
    "          loss = criterion(outputs, y)\n",
    "          test_loss += loss.item() * 23\n",
    "      test_losses.append(test_loss)\n",
    "    \n",
    "  print('{}, epoch {}, train loss: {}, test loss: {}, average test_loss {}'.format(test_app, epoch, running_loss, test_loss, sum(test_losses)/len(test_losses) ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kXCNXDjh593M"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from predict import predict\n",
    "from plot_execution_times import plot_execution_times\n",
    "\n",
    "\n",
    "predictions = predict(net, 32, test_set)\n",
    "\n",
    "print('Test Loss:', mean_squared_error(test_set[:,-5:], predictions))\n",
    "plot_execution_times(predictions, test_set[:, -5:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z_oxd90l593P"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of SELECT TEST APP HERCAHERCULES.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
